---
layout: post
title: 网络爬虫——由模拟登录扯开去
tags: Spider
---
## 模拟登录
机器学习、深度学习、人工智能大都离不开海量数据的支撑，网络爬虫便是数据的一种来源，而对于大部分站点，需要登录后才有权限进行相应的操作。这里简单谈谈自己在给朋友做一些自动化工具过程中关于模拟登录的体会（仅限于自己实际环境中遇到的站点）。

公司并没有此类需求，自己也没专门学过爬虫，只是有时周末从网上看了几个例子，就直接在浏览器中抓取网络请求，分析请求、响应。也掉了不少坑，有的填上了，有的还在那里。。

## 一般步骤
模拟登录的一般步骤：真实的目标地址，FormData，头信息，Cookie，重定向。

> F12打开开发者工具 ——> Network ——> 勾选Preserve log ——> 输入账号、密码等，点击登录 ——> 分析请求

- 获取、分析请求

![2017-12-25-Request](https://github.com/heartsuit/heartsuit.github.io/raw/master/pictures/2017-12-25-Request.png)

- 请求头信息

![2017-12-25-Header](https://github.com/heartsuit/heartsuit.github.io/raw/master/pictures/2017-12-25-Header.png)

Note：
1. 并非所有的网站登录都有`FormData`，比如有的*Java Web*站点就是通过`action`的方式提交form 的表单数据，用户信息是以input的name作为属性名的键值对，提交到服务器。
2. 如果发现无法获取到有用的信息，可通过其他软件（eg: `fiddler`， 也可用于移动端抓包）对网络请求进行抓包，然后分析。

## 分类

### 1. 账号，密码（明文）POST

最简单的方式，直接提交即可；

### 2. 账号，密码（密文）POST

根据不同的场景分别处理：
- 需求：使用单个账号，登录一个目标网站，之后做各种处理；

  这时，直接用`FormData`中加密后的密码提交；

- 需求：使用大量账号，登录一个目标网站；

  这就要确定目标网站前端所采用的密码加密算法，常见的有`MD5`，`RSA`等；一般可以在前端JavaScript脚本中找到相关的加密方式；

  Note: 
  1. 有时候会辅以`token+密码`的形式，而不仅仅是原密码进行加密（见第3种情况）；
  2. 如果所有账号的密码都一样，此时也用不着确定加密算法了，可按前一种需求处理；

### 3. 账号，token+密码（密文）POST

首先要想办法获取token，token又有动、静之分：

  - 动态token：每次打开登录页面后，都会返回一个不同的token，这需要分析页面信息，做相应的处理；
  - 静态token：这种一般是在服务端定义好的一个固定密钥；当时遇到的是移动端的app，通过反编译安卓客户端软件.apk得到源码，从中找到的（忘记在请求中是否可以抓取到）……


### 4. 账号，上述任一情况，图片验证码 POST
这里同第2种情况，对于图片验证码，可根据需求分别处理：eg：

- 需求：使用单个账号，登录一个目标网站，之后做各种处理；

**Solution**：
> 这时，登录一次就可以，所以可将目标验证码下载下来，显示图片，人工识别即可；

- 需求：使用大量账号，登录一个目标网站，之后均做同样的操作与处理（具体场景，可自由发挥想象力）；

**Solution**：
> 由于需要重复进行登录动作，最简单的方法是扔给第三方平台（嗯，可能是人肉识别），这类平台一般需要充值、进行付费识别（正确率还可以，错误的可以报回给平台）；

> 高级一点的可利用`OCR`技术，再辅以图像处理技术，一般步骤是先处理图片，灰度化，去除背景色及噪点，提高对比度等，这有赖于图像处理算法能力，也有不少的库可以用，比如`ImageMagick`，然后通过`OCR`识别，推荐`tesseract-ocr`；对于容易识别的验证码可粗暴一点，直接由`OCR`识别，错了换一张就是了；

> 比较专业的是通过机器学习、神经网络等进行训练，然后喂给它新的图片，完成识别；这种方法对技术的要求挺高（一般都是调用现成的算法包，那也挺复杂的。。），虽然我的硕士研究方向是脑电信号处理，也用到了不少机器学习算法，可是最终还是没选择这条路，各有各的一片天地吧。


## 头信息
这里主要提一下涉及到异步请求时，`'X-Requested-With':'XMLHttpRequest'`这个头信息必须要添加上，否则无法返回正常的结果；

页面中有时是以异步的方式发出请求，而有时请求又是同步的，所以需要动态添加、删除这个**请求头信息**。

## Cookie
用户名、密码提交到服务器后，如果登录成功，那么服务器一般会返回Cookie，可从**响应头信息**的`set-cookie`获取到，在登录的后续操作中，都要携带这一Cookie发送请求；

对于有验证码的站点，需要注意的是，第一步获取到验证码后，有个与验证码附在一起的Cookie，所以，此时整个登录过程，会涉及到两个Cookie：验证码Cookie与登录后的Cookie，简要描述为：
1. 获取验证码时，随验证码返回Cookie，记作Cookie1；
2. 向服务器发送登录请求时，表单数据携带Cookie1， POST；
3. 登录成功，返回Cookie，记作Cookie2；
4. 正常情况下，后续操作的每次请求附带Cookie2即可；

## 重定向
HTTP Code 为`3xx`开头的响应（eg: 301, 302），即表示重定向，在登录请求发出后，返回的响应出现此类情况时，先莫慌，这表明页面发生了跳转，可以修改请求配置以实现对跳转的跟踪，完成登录。

## 反爬虫

> 道高一尺，魔高一丈，既然有爬虫，那么就有反爬虫，技术也正是在这样的不断博弈中向前推动。

通过以上步骤后，基本可以完成登录，之后就可以开心的玩耍了。。
但是，还要知道，有一个叫“反爬虫”的存在，不管出于什么目的的反爬虫，都是为了防止自己的网站不被其他人`自动化、大批量`地获取网站信息，尤其是对可能造成服务器压力大增的请求，需要实施拦截。所以完成模拟登录后，不能肆无忌惮地乱来，一定要注意请求的频率，考虑下目标服务器的压力，完成我们的需求即可，若完全是以恶意的方式企图搞垮人家的服务器，我祈祷你的账号、IP被封掉~

来看看[丧心病狂的反爬虫](http://baijiahao.baidu.com/s?id=1572788572555517&wfr=spider&for=pc)😊

## 总结

以上简单介绍了几种不同类型模拟登录的思路，之后的数据抓取、处理，存储，以及设计高级的爬虫，这些都有很深的学问，慢慢摸索吧~~